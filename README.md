# data-engineering-portfolio
Showcases hands-on data engineering projects focused on building scalable, reliable, and efficient data pipelines using modern tools and cloud technologies
# ðŸ§  Data Engineering Portfolio

Welcome! This repository showcases a collection of real-world data engineering projects built with modern technologies and best practices. The goal is to demonstrate expertise in designing and implementing scalable, efficient, and production-ready data pipelines.

## ðŸš€ Overview

This portfolio includes use cases involving:

- Data ingestion and transformation (ETL/ELT)
- Cloud-based workflows using Azure
- Batch and distributed data processing with PySpark
- SQL optimization and analytics
- Delta Lake architecture and schema evolution
- DataOps principles and automation

## ðŸ§° Tech Stack

| Category                | Technologies                                                                 |
|------------------------|-------------------------------------------------------------------------------|
| Programming            | Python, PySpark                                                               |
| Databases              | MySQL, SQL Server, PostgreSQL, DuckDB                                         |
| Big Data               | Apache Spark, Delta Lake                                                      |
| Cloud Platform         | Microsoft Azure (Data Factory, Databricks, Synapse, Key Vault, Blob Storage) |
| Orchestration & Infra  | Azure Functions, Scheduling, CI/CD                                            |
| Data Manipulation      | Pandas, SQL                                                                   |


